---
layout: single
title:  "markdown test"
categories : blog_setting
tag : [markdown, 블로그, 설정]
toc: true
toc_sticky: true
---



# 6 Topic modeling
텍스트 마이닝에서는 블로그 게시물이나 뉴스 기사와 같은 문서 모음이 있는 경우가 많으며, 이를 개별적으로 이해할 수 있도록 자연스러운 그룹으로 나누려고 합니다. 토픽 모델링은 우리가 무엇을 찾고 있는지 확실하지 않은 경우에도 자연스러운 항목 그룹을 찾는 숫자 데이터에 대한 클러스터링과 유사한 이러한 문서의 감독되지 않은 분류를 위한 방법입니다.

LDA(Latent Dirichlet Allocation)는 주제 모델을 피팅하는 데 특히 널리 사용되는 방법입니다. 각 문서를 주제의 혼합물로 취급하고 각 주제를 단어의 혼합물로 취급합니다. 이를 통해 문서는 자연어의 일반적인 사용을 반영하는 방식으로 개별 그룹으로 분리되지 않고 콘텐츠 측면에서 서로 "겹칠" 수 있습니다

![ ](C:\\Users\\user\\Desktop\\세미나수업\\텍스트분석흐름도.png)

그림 6.1: 주제 모델링을 통합한 텍스트 분석의 흐름도. topicmodels 패키지는 Document-Term Matrix를 입력으로 사용하고 dplyr 및 ggplot2로 조작 및 시각화할 수 있도록 깔끔한 텍스트로 정리할 수 있는 모델을 생성합니다.

그림 6.1 에서 볼 수 있듯이 이 책 전체에서 사용한 것과 동일한 깔끔한 도구 세트로 주제 모델링에 접근하기 위해 깔끔한 텍스트 원칙을 사용할 수 있습니다. 이 장에서는 topicmodels 패키지LDA 의 객체 로 작업하는 방법을 배웁니다 . 특히 ggplot2 및 dplyr로 조작할 수 있도록 이러한 모델을 정리합니다. 또한 여러 책의 챕터를 클러스터링하는 예를 살펴보겠습니다. 여기서 주제 모델은 텍스트 내용을 기반으로 네 책의 차이점을 "학습"하는 것을 볼 수 있습니다.



## 6.1 Latent Dirichlet allocation
잠재 디리클레 할당은 주제 모델링을 위한 가장 일반적인 알고리즘 중 하나입니다. 모델 이면의 수학에 대해 자세히 알아보지 않고도 두 가지 원칙에 따라 모델을 이해할 수 있습니다.

모든 문서는 주제가 혼합되어 있습니다. 우리는 각 문서가 특정 비율로 여러 주제의 단어를 포함할 수 있다고 상상합니다. 예를 들어, 2개 주제 모델에서 "문서 1은 주제 A 90%, 주제 B 10%이고 문서 2는 주제 A 30%, 주제 B 70%"라고 말할 수 있습니다.
모든 주제는 단어의 혼합입니다. 예를 들어, 하나의 주제는 "정치"이고 다른 하나는 "엔터테인먼트"인 미국 뉴스의 두 가지 주제 모델을 상상할 수 있습니다. 정치 주제에서 가장 많이 사용되는 단어는 "대통령", "국회" 및 "정부"일 수 있으며 엔터테인먼트 주제는 "영화", "텔레비전" 및 "배우"와 같은 단어로 구성될 수 있습니다. 중요한 것은 단어가 주제 간에 공유될 수 있다는 것입니다. "예산"과 같은 단어는 둘 다에 동등하게 나타날 수 있습니다.
LDA는 이 두 가지를 동시에 추정하는 수학적 방법입니다. 각 항목과 관련된 단어의 조합을 찾는 동시에 각 문서를 설명하는 항목의 조합을 결정합니다. 이 알고리즘의 기존 구현이 많이 있으며 그 중 하나를 자세히 살펴보겠습니다.

5 장에서는 AssociatedPressDocumentTermMatrix의 예로 topicmodels 패키지에서 제공하는 데이터 세트 를 간략하게 소개했습니다 . 이것은 대부분 1988년경에 발행된 미국 통신사의 2246개 뉴스 기사 모음입니다.

```R
# install.packages('topicmodels')

library(topicmodels)

data("AssociatedPress")
AssociatedPress
```
LDA()topicmodels 패키지의 기능인 setting 을 사용 k = 2하여 2개 주제 LDA 모델을 생성할 수 있습니다.

실제로 거의 모든 주제 모델은 더 큰 을 사용 k하지만 곧 이 분석 접근 방식이 더 많은 수의 주제로 확장된다는 것을 알게 될 것입니다.

이 함수는 단어가 주제와 연관되는 방식 및 주제가 문서와 연관되는 방식과 같은 모델 적합의 전체 세부 정보를 포함하는 객체를 반환합니다.

```R
# set a seed so that the output of the model is predictable
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
```
모델을 맞추는 것은 "쉬운 부분"이었습니다. 나머지 분석에는 kiddytext 패키지의 정리 기능을 사용하여 모델을 탐색하고 해석하는 작업이 포함됩니다.



## 6.1.1 Word-topic probabilities


```{r , warning=FALSE, message = FALSE}
library(tidytext)

ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
library(ggplot2)
library(dplyr)

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)
ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
library(tidyr)

beta_wide <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_wide
```

## 6.1.2 Document-topic probabilities

```{r , warning=FALSE, message = FALSE}
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents
tidy(AssociatedPress) %>%
  filter(document == 6) %>%
  arrange(desc(count))
```

## 6.2 Example: the great library heist

```R
titles <- c("Twenty Thousand Leagues under the Sea", 
            "The War of the Worlds",
            "Pride and Prejudice", 
            "Great Expectations")
library(gutenbergr)

books <- gutenberg_works(title %in% titles) %>%
  gutenberg_download(meta_fields = "title")
library(stringr)
# divide into documents, each representing one chapter
by_chapter <- books %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(
    text, regex("^chapter ", ignore_case = TRUE)
  ))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, title, chapter)

# split into words
by_chapter_word <- by_chapter %>%
  unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE)

word_counts
```

##  6.2.1 LDA on chapters


```R
chapters_dtm <- word_counts %>%
  cast_dtm(document, word, n)

chapters_dtm
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda
chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics
top_terms <- chapter_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 5) %>% 
  ungroup() %>%
  arrange(topic, -beta)

top_terms
library(ggplot2)

top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

## 6.2.2 Per-document classification

```{r , warning=FALSE, message = FALSE}
chapters_gamma <- tidy(chapters_lda, matrix = "gamma")
chapters_gamma
chapters_gamma <- chapters_gamma %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)

chapters_gamma
# reorder titles in order of topic 1, topic 2, etc before plotting
chapters_gamma %>%
  mutate(title = reorder(title, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ title) +
  labs(x = "topic", y = expression(gamma))
chapter_classifications <- chapters_gamma %>%
  group_by(title, chapter) %>%
  slice_max(gamma) %>%
  ungroup()
book_topics <- chapter_classifications %>%
  count(title, topic) %>%
  group_by(title) %>%
  slice_max(n, n = 1) %>% 
  ungroup() %>%
  transmute(consensus = title, topic)
chapter_classifications %>%
  inner_join(book_topics, by = "topic") %>%
  filter(title != consensus)
```


## 6.2.3 By word assignments: augment

```{r , warning=FALSE, message = FALSE}
chapter_classifications
assignments <- augment(chapters_lda, data = chapters_dtm)
assignments
assignments <- assignments %>%
  separate(document, c("title", "chapter"), 
           sep = "_", convert = TRUE) %>%
  inner_join(book_topics, by = c(".topic" = "topic"))
assignments
library(scales)
assignments %>%
  count(title, consensus, wt = count) %>%
  mutate(across(c(title, consensus), ~str_wrap(., 20))) %>%
  group_by(title) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(consensus, title, fill = percent)) +
  geom_tile() +
  scale_fill_gradient2(high = "darkred", label = percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.grid = element_blank()) +
  labs(x = "Book words were assigned to",
       y = "Book words came from",
       fill = "% of assignments")
wrong_words <- assignments %>%
  filter(title != consensus)
wrong_words
wrong_words %>%
  count(title, consensus, term, wt = count) %>%
  ungroup() %>%
  arrange(desc(n))
word_counts %>%
  filter(word == "flopson")
```

## 6.3 Alternative LDA implementations

```{r , warning=FALSE, message = FALSE}
# install.packages('mallet')

library(mallet)
# create a vector with one string per chapter
collapsed <- by_chapter_word %>%
  anti_join(stop_words, by = "word") %>%
  mutate(word = str_replace(word, "'", "")) %>%
  group_by(document) %>%
  summarize(text = paste(word, collapse = " "))
# create an empty file of "stopwords"
file.create(empty_file <- tempfile())
docs <- mallet.import(collapsed$document, collapsed$text, empty_file)

mallet_model <- MalletLDA(num.topics = 4)
mallet_model$loadDocuments(docs)
mallet_model$train(100)
# word-topic pairs
tidy(mallet_model)
# document-topic pairs
tidy(mallet_model, matrix = "gamma")
# column needs to be named "term" for "augment"
term_counts <- rename(word_counts, term = word)
augment(mallet_model, term_counts)

```

## 6.4 Summary
